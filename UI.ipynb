{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO(\"./best.pt\")\n",
    "\n",
    "def detect_image(image):\n",
    "    model = YOLO(\"./best.pt\")  # ëª¨ë¸ ë¡œë“œ\n",
    "    results = model.predict(image, imgsz=1280, save=False)  # YOLO ì˜ˆì¸¡ ì‹¤í–‰\n",
    "    \n",
    "    result_image = results[0].plot()  # ì˜ˆì¸¡ ê²°ê³¼ ì´ë¯¸ì§€ ë³€í™˜\n",
    "    return result_image  # ê²°ê³¼ ë°˜í™˜\n",
    "\n",
    "# Gradio UI ì„¤ì •\n",
    "demo = gr.Interface(\n",
    "    fn=detect_image,  # ì´ë¯¸ì§€ ë¶„ì„ í•¨ìˆ˜\n",
    "    inputs=gr.Image(type=\"numpy\"),  # ìž…ë ¥: ì´ë¯¸ì§€ ì—…ë¡œë“œ\n",
    "    outputs=gr.Image(type=\"numpy\"),  # ì¶œë ¥: ë¶„ì„ëœ ì´ë¯¸ì§€\n",
    "    title=\"YOLO Image Detection\",  # UI ì œëª©\n",
    "    description=\"Upload an image to detect objects using YOLO model.\"\n",
    ")\n",
    "\n",
    "demo.launch(share=True)  # UI ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import ffmpeg\n",
    "\n",
    "# YOLO ëª¨ë¸ ë¡œë“œ\n",
    "model = YOLO(\"./best.pt\")\n",
    "\n",
    "def detect_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # FPS ë³´ì • (0ì´ë©´ ìµœì†Œ 1ë¡œ ì„¤ì •)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    fps = max(1, fps)  # 0ì´ë©´ 1ë¡œ ì„¤ì •\n",
    "\n",
    "\n",
    "    # ìž„ì‹œ íŒŒì¼ ìƒì„±\n",
    "    temp_out_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\").name\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # macOSì—ì„œëŠ” 'mp4v', WindowsëŠ” 'XVID' ê°€ëŠ¥\n",
    "    out = cv2.VideoWriter(temp_out_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # YOLO ëª¨ë¸ ì˜ˆì¸¡ --> cuda ì‚¬ìš©ê°€ëŠ¥í•˜ë©´ device=\"cuda\"ë¡œ ë³€ê²½, cpuëŠ” device í•­ëª© ì œê±°. í˜„ìž¬ëŠ” MACì˜ mps ì‚¬ìš©\n",
    "        results = model.predict(frame, imgsz=1280, save=False, device=\"mps\")\n",
    "        result_frame = results[0].plot()\n",
    "        \n",
    "        # ê²°ê³¼ í”„ë ˆìž„ ì €ìž¥ (float í˜•ì‹ì¼ ê²½ìš° uint8ë¡œ ë³€í™˜)\n",
    "        if result_frame.dtype != np.uint8:\n",
    "            result_frame = (result_frame * 255).astype(np.uint8)\n",
    "        \n",
    "        out.write(result_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    return temp_out_path  # ê°ì§€ëœ ë¹„ë””ì˜¤ ê²½ë¡œ ë°˜í™˜\n",
    "\n",
    "# Gradio UI ì„¤ì •\n",
    "demo = gr.Interface(\n",
    "    fn=detect_video,\n",
    "    inputs=gr.Video(format=\"mp4\"),  # 'type' ëŒ€ì‹  'format' ì‚¬ìš©\n",
    "    outputs=gr.Video(format=\"mp4\"),  # mp4 í˜•ì‹ ì§€ì •\n",
    "    title=\"YOLO Video Detection\",\n",
    "    description=\"Upload a video to detect objects using YOLO model.\"\n",
    ")\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import torch\n",
    "import subprocess\n",
    "import ffmpeg\n",
    "\n",
    "# YOLO ëª¨ë¸ ë¡œë“œ (GPU ë˜ëŠ” MPS ì§€ì› ì„¤ì •)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = YOLO(\"./best.pt\").to(device)\n",
    "\n",
    "def detect_video(video_path, frame_skip=2):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # FPS ë³´ì • (0ì´ë©´ ê¸°ë³¸ê°’ 30fpsë¡œ ì„¤ì •)\n",
    "    fps = fps if fps > 0 else 30\n",
    "\n",
    "    # OpenCV VideoWriterë¥¼ ì‚¬ìš©í•˜ì—¬ ìž„ì‹œ AVI íŒŒì¼ ì €ìž¥\n",
    "    temp_out_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".avi\").name\n",
    "    temp_final_out = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\").name  # ìµœì¢… ë³€í™˜ëœ MP4 íŒŒì¼\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # 'XVID'ëŠ” ëŒ€ë¶€ë¶„ì˜ OSì—ì„œ í˜¸í™˜ë¨\n",
    "    out = cv2.VideoWriter(temp_out_path, fourcc, fps, (width, height))\n",
    "\n",
    "    frame_count = 0\n",
    "    frames = []\n",
    "    results_cache = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_skip == 0:\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) >= 4:\n",
    "                results = model.predict(frames, imgsz=640, device=device, save=False)\n",
    "                results_cache.extend(results)\n",
    "                frames = []\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    if frames:\n",
    "        results = model.predict(frames, imgsz=640, device=device, save=False)\n",
    "        results_cache.extend(results)\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_skip == 0:\n",
    "            result_frame = results_cache.pop(0).plot()\n",
    "            result_frame = cv2.cvtColor(result_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if result_frame.dtype != np.uint8:\n",
    "                result_frame = (result_frame * 255).astype(np.uint8)\n",
    "\n",
    "            out.write(result_frame)\n",
    "        else:\n",
    "            out.write(frame)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # `subprocess`ë¥¼ ì‚¬ìš©í•˜ì—¬ ffmpegë¡œ MP4 ë³€í™˜\n",
    "    subprocess.run([\n",
    "        \"/Users/k23070952/Library/Python/3.9/lib/python/site-packages/ffmpeg\", \"-i\", temp_out_path, \"-vcodec\", \"libx264\", \"-crf\", \"23\", temp_final_out, \"-y\"\n",
    "    ], check=True)\n",
    "\n",
    "    # ë³€í™˜ í›„ ì›ë³¸ AVI íŒŒì¼ ì‚­ì œ\n",
    "    os.remove(temp_out_path)\n",
    "\n",
    "    return temp_final_out  # ë³€í™˜ëœ MP4 íŒŒì¼ ë°˜í™˜\n",
    "\n",
    "# âœ… **Gradio UI ìˆ˜ì • (ê¸°ë³¸ `gr.Video` ì‚¬ìš©)**\n",
    "demo = gr.Interface(\n",
    "    fn=detect_video,\n",
    "    inputs=[\n",
    "        gr.Video(format=\"mp4\"),  # ë™ì˜ìƒ ì—…ë¡œë“œ\n",
    "        gr.Slider(1, 5, value=2, step=1, label=\"Frame Skip\")  # í”„ë ˆìž„ ìŠ¤í‚µ ì„¤ì •\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Video(format=\"mp4\"),  # ðŸš€ Gradioì—ì„œ ì§ì ‘ ë¹„ë””ì˜¤ ìž¬ìƒ ê°€ëŠ¥!\n",
    "        gr.File(label=\"Download Processed Video\")  # ðŸ“¥ ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ\n",
    "    ],\n",
    "    title=\"YOLO Video Detection\",\n",
    "    description=\"Upload a video to detect objects using YOLO model. Adjust frame skip to speed up processing.\"\n",
    ")\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7886\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import ffmpeg\n",
    "\n",
    "# YOLO ëª¨ë¸ ë¡œë“œ\n",
    "model = YOLO(\"./best.pt\")\n",
    "\n",
    "def detect_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # FPS ë³´ì • (0ì´ë©´ ìµœì†Œ 1ë¡œ ì„¤ì •)\n",
    "    fps = max(1, fps)  \n",
    "\n",
    "    # ìž„ì‹œ ì›ë³¸ ì¶œë ¥ ë¹„ë””ì˜¤ (mp4v ì½”ë±)\n",
    "    temp_out_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\").name\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  \n",
    "    out = cv2.VideoWriter(temp_out_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # YOLO ëª¨ë¸ ì˜ˆì¸¡\n",
    "        results = model.predict(frame, imgsz=1280, save=False, device=\"mps\")\n",
    "        result_frame = results[0].plot()\n",
    "        \n",
    "        # ê²°ê³¼ í”„ë ˆìž„ ì €ìž¥ (float í˜•ì‹ì¼ ê²½ìš° uint8ë¡œ ë³€í™˜)\n",
    "        if result_frame.dtype != np.uint8:\n",
    "            result_frame = (result_frame * 255).astype(np.uint8)\n",
    "        \n",
    "        out.write(result_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    # âœ… ë¹„ë””ì˜¤ë¥¼ H.264 (AVC) ì½”ë±ìœ¼ë¡œ ë³€í™˜ (ë¸Œë¼ìš°ì € í˜¸í™˜)\n",
    "    temp_h264_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\").name\n",
    "    ffmpeg.input(temp_out_path).output(temp_h264_path, vcodec=\"libx264\", crf=23).run(overwrite_output=True)\n",
    "    \n",
    "    # ì›ë³¸ ìž„ì‹œ íŒŒì¼ ì‚­ì œ\n",
    "    os.remove(temp_out_path)\n",
    "\n",
    "    return temp_h264_path  # ë³€í™˜ëœ ë¹„ë””ì˜¤ ê²½ë¡œ ë°˜í™˜\n",
    "\n",
    "# Gradio UI ì„¤ì •\n",
    "demo = gr.Interface(\n",
    "    fn=detect_video,\n",
    "    inputs=gr.Video(format=\"mp4\"),\n",
    "    outputs=gr.Video(format=\"mp4\"),  \n",
    "    title=\"YOLO Video Detection\",\n",
    "    description=\"Upload a video to detect objects using YOLO model.\"\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: ffmpeg 1.4\n",
      "Uninstalling ffmpeg-1.4:\n",
      "  Successfully uninstalled ffmpeg-1.4\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ffmpeg-python in /Users/k23070952/Library/Python/3.9/lib/python/site-packages (0.2.0)\n",
      "Requirement already satisfied: future in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from ffmpeg-python) (0.18.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall ffmpeg -y\n",
    "!pip install ffmpeg-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: ffmpeg\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -version\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
