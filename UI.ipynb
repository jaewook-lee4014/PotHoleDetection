{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO(\"./best.pt\")\n",
    "\n",
    "def detect_image(image):\n",
    "    model = YOLO(\"./best.pt\")  # 모델 로드\n",
    "    results = model.predict(image, imgsz=1280, save=False)  # YOLO 예측 실행\n",
    "    \n",
    "    result_image = results[0].plot()  # 예측 결과 이미지 변환\n",
    "    return result_image  # 결과 반환\n",
    "\n",
    "# Gradio UI 설정\n",
    "demo = gr.Interface(\n",
    "    fn=detect_image,  # 이미지 분석 함수\n",
    "    inputs=gr.Image(type=\"numpy\"),  # 입력: 이미지 업로드\n",
    "    outputs=gr.Image(type=\"numpy\"),  # 출력: 분석된 이미지\n",
    "    title=\"YOLO Image Detection\",  # UI 제목\n",
    "    description=\"Upload an image to detect objects using YOLO model.\"\n",
    ")\n",
    "\n",
    "demo.launch(share=True)  # UI 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputting Data as a File!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 54\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# 파일 업로드 후 실행 (프레임 단위 스트리밍)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     video_input\u001b[38;5;241m.\u001b[39mupload(\n\u001b[1;32m     49\u001b[0m         fn\u001b[38;5;241m=\u001b[39mdetect_video_stream,\n\u001b[1;32m     50\u001b[0m         inputs\u001b[38;5;241m=\u001b[39m[video_input],\n\u001b[1;32m     51\u001b[0m         outputs\u001b[38;5;241m=\u001b[39m[video_output],\n\u001b[1;32m     52\u001b[0m     )\n\u001b[0;32m---> 54\u001b[0m demo\u001b[38;5;241m.\u001b[39mlaunch(share\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/gradio/blocks.py:2701\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[0;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, _frontend)\u001b[0m\n\u001b[1;32m   2699\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2701\u001b[0m         share_url \u001b[38;5;241m=\u001b[39m networking\u001b[38;5;241m.\u001b[39msetup_tunnel(\n\u001b[1;32m   2702\u001b[0m             local_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_name,\n\u001b[1;32m   2703\u001b[0m             local_port\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_port,\n\u001b[1;32m   2704\u001b[0m             share_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_token,\n\u001b[1;32m   2705\u001b[0m             share_server_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_server_address,\n\u001b[1;32m   2706\u001b[0m         )\n\u001b[1;32m   2707\u001b[0m         parsed_url \u001b[38;5;241m=\u001b[39m urlparse(share_url)\n\u001b[1;32m   2708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url \u001b[38;5;241m=\u001b[39m urlunparse(\n\u001b[1;32m   2709\u001b[0m             (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_server_protocol,) \u001b[38;5;241m+\u001b[39m parsed_url[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m   2710\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/gradio/networking.py:47\u001b[0m, in \u001b[0;36msetup_tunnel\u001b[0;34m(local_host, local_port, share_token, share_server_address)\u001b[0m\n\u001b[1;32m     45\u001b[0m     remote_port \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(remote_port)\n\u001b[1;32m     46\u001b[0m tunnel \u001b[38;5;241m=\u001b[39m Tunnel(remote_host, remote_port, local_host, local_port, share_token)\n\u001b[0;32m---> 47\u001b[0m address \u001b[38;5;241m=\u001b[39m tunnel\u001b[38;5;241m.\u001b[39mstart_tunnel()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m address\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/gradio/tunneling.py:103\u001b[0m, in \u001b[0;36mTunnel.start_tunnel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_tunnel\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_binary()\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_tunnel(BINARY_PATH)\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/gradio/tunneling.py:138\u001b[0m, in \u001b[0;36mTunnel._start_tunnel\u001b[0;34m(self, binary)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(\n\u001b[1;32m    135\u001b[0m     command, stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m atexit\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill)\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_url_from_tunnel_stream()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/gradio/tunneling.py:160\u001b[0m, in \u001b[0;36mTunnel._read_url_from_tunnel_stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[1;32m    161\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m line \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import uuid\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLO 모델 로드\n",
    "model = YOLO(\"./best.pt\")\n",
    "\n",
    "# 비디오 프레임 처리를 위한 함수\n",
    "def process_frame(frame):\n",
    "    \"\"\" YOLO 모델을 사용하여 프레임을 감지하고, 바운딩 박스를 그린 후 반환 \"\"\"\n",
    "    results = model.predict(frame, imgsz=1280, save=False, device=\"mps\")  # Mac MPS 사용\n",
    "    result_frame = results[0].plot()\n",
    "\n",
    "    # 결과 프레임이 float 형식이라면 uint8로 변환\n",
    "    if result_frame.dtype != np.uint8:\n",
    "        result_frame = (result_frame * 255).astype(np.uint8)\n",
    "\n",
    "    return result_frame\n",
    "\n",
    "# 비디오 감지 함수 (Gradio 스트리밍 지원, FFmpeg 없이)\n",
    "def detect_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # 비디오 속성 가져오기\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fps = max(1, fps)  # FPS가 0이면 최소 1로 설정\n",
    "\n",
    "    # UUID 기반으로 고유한 파일명 생성\n",
    "    output_video_name = f\"output_{uuid.uuid4()}.avi\"  # AVI로 저장하여 FFmpeg 필요 없음\n",
    "\n",
    "    # MP4 대신 AVI 사용 (Gradio가 AVI 지원)\n",
    "    video_codec = cv2.VideoWriter_fourcc(*\"XVID\")  \n",
    "    output_video = cv2.VideoWriter(output_video_name, video_codec, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        processed_frame = process_frame(frame)  # YOLO 감지 수행\n",
    "        output_video.write(processed_frame)  # 결과 저장\n",
    "\n",
    "    cap.release()\n",
    "    output_video.release()\n",
    "\n",
    "    return output_video_name  # 최종 비디오 반환\n",
    "\n",
    "# Gradio UI 설정\n",
    "with gr.Blocks() as demo:\n",
    "    gr.HTML(\"<h1 style='text-align: center'>YOLO Video Detection</h1>\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            video_input = gr.Video(label=\"Upload Video\")\n",
    "        with gr.Column():\n",
    "            output_video = gr.File(label=\"Download Processed Video\")  # 파일 다운로드 가능하도록 변경\n",
    "    \n",
    "    # 파일 업로드 후 실행\n",
    "    video_input.upload(\n",
    "        fn=detect_video,\n",
    "        inputs=[video_input],\n",
    "        outputs=[output_video],\n",
    "    )\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-time detection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "Could not create share link. Missing file: /Users/k23070952/.local/lib/python3.12/site-packages/gradio/frpc_darwin_arm64_v0.3. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_darwin_arm64\n",
      "2. Rename the downloaded file to: frpc_darwin_arm64_v0.3\n",
      "3. Move the file to this location: /Users/k23070952/.local/lib/python3.12/site-packages/gradio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLO 모델 로드\n",
    "model = YOLO(\"./best.pt\")\n",
    "\n",
    "# 비디오 감지 함수 (프레임 스킵 추가)\n",
    "def detect_video_stream(video_path, frame_skip=2):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_count = 0  # 프레임 카운트 초기화\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # 프레임 스킵 적용 (프레임을 건너뛰면서 처리)\n",
    "        if frame_count % frame_skip == 0:\n",
    "            # YOLO 감지 수행\n",
    "            results = model.predict(frame, imgsz=1280, save=False, device=\"mps\")  # Mac MPS 사용\n",
    "            result_frame = results[0].plot()\n",
    "\n",
    "            # OpenCV의 BGR을 RGB로 변환 (Gradio에서 정상 표시되도록)\n",
    "            result_frame = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # numpy 배열을 반환 (Gradio `gr.Image`에서 정상 표시 가능)\n",
    "            yield result_frame\n",
    "        \n",
    "        frame_count += 1  # 프레임 카운트 증가\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Gradio UI 설정 (Start AI Detection! 버튼 추가)\n",
    "with gr.Blocks() as demo:\n",
    "    gr.HTML(\"<h1 style='text-align: center; font-size: 24px;'>🚀 YOLO Video Detection (Real-Time Streaming)</h1>\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "                gr.Markdown(\"### 🎥 Upload Your Video\")\n",
    "                video_input = gr.Video(label=\"Upload Video\")\n",
    "                frame_skip_slider = gr.Slider(\n",
    "                    minimum=1, maximum=10, step=1, value=2, \n",
    "                    label=\"🎞️ Frame Skip (Higher = Faster Processing)\"\n",
    "                )\n",
    "                start_button = gr.Button(\"🚀 Start AI Detection!\", variant=\"primary\")  # 실행 버튼 추가\n",
    "\n",
    "        with gr.Column():\n",
    "                gr.Markdown(\"### 📊 Processed Video Stream\")\n",
    "                video_output = gr.Image(label=\"Processed Video\", streaming=True, height=480)  # 원래대로 유지\n",
    "    \n",
    "    # \"Start AI Detection!\" 버튼을 클릭하면 감지 실행\n",
    "    start_button.click(\n",
    "        fn=detect_video_stream,\n",
    "        inputs=[video_input, frame_skip_slider],  # 프레임 스킵 옵션 추가\n",
    "        outputs=[video_output],\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
