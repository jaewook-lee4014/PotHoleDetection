{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO(\"./best.pt\")\n",
    "\n",
    "def detect_image(image):\n",
    "    model = YOLO(\"./best.pt\")  # 모델 로드\n",
    "    results = model.predict(image, imgsz=1280, save=False)  # YOLO 예측 실행\n",
    "    \n",
    "    result_image = results[0].plot()  # 예측 결과 이미지 변환\n",
    "    return result_image  # 결과 반환\n",
    "\n",
    "# Gradio UI 설정\n",
    "demo = gr.Interface(\n",
    "    fn=detect_image,  # 이미지 분석 함수\n",
    "    inputs=gr.Image(type=\"numpy\"),  # 입력: 이미지 업로드\n",
    "    outputs=gr.Image(type=\"numpy\"),  # 출력: 분석된 이미지\n",
    "    title=\"YOLO Image Detection\",  # UI 제목\n",
    "    description=\"Upload an image to detect objects using YOLO model.\"\n",
    ")\n",
    "\n",
    "demo.launch(share=True)  # UI 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import ffmpeg\n",
    "\n",
    "# YOLO 모델 로드\n",
    "model = YOLO(\"./best.pt\")\n",
    "\n",
    "def detect_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # 비디오 정보 가져오기\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # FPS 보정 (0이면 최소 1로 설정)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    fps = max(1, fps)  # 0이면 1로 설정\n",
    "\n",
    "\n",
    "    # 임시 파일 생성\n",
    "    temp_out_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\").name\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # macOS에서는 'mp4v', Windows는 'XVID' 가능\n",
    "    out = cv2.VideoWriter(temp_out_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # YOLO 모델 예측 --> cuda 사용가능하면 device=\"cuda\"로 변경, cpu는 device 항목 제거. 현재는 MAC의 mps 사용\n",
    "        results = model.predict(frame, imgsz=1280, save=False, device=\"mps\")\n",
    "        result_frame = results[0].plot()\n",
    "        \n",
    "        # 결과 프레임 저장 (float 형식일 경우 uint8로 변환)\n",
    "        if result_frame.dtype != np.uint8:\n",
    "            result_frame = (result_frame * 255).astype(np.uint8)\n",
    "        \n",
    "        out.write(result_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    return temp_out_path  # 감지된 비디오 경로 반환\n",
    "\n",
    "# Gradio UI 설정\n",
    "demo = gr.Interface(\n",
    "    fn=detect_video,\n",
    "    inputs=gr.Video(format=\"mp4\"),  # 'type' 대신 'format' 사용\n",
    "    outputs=gr.Video(format=\"mp4\"),  # mp4 형식 지정\n",
    "    title=\"YOLO Video Detection\",\n",
    "    description=\"Upload a video to detect objects using YOLO model.\"\n",
    ")\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import torch\n",
    "import subprocess\n",
    "import ffmpeg\n",
    "\n",
    "# YOLO 모델 로드 (GPU 또는 MPS 지원 설정)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = YOLO(\"./best.pt\").to(device)\n",
    "\n",
    "def detect_video(video_path, frame_skip=2):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # 비디오 정보 가져오기\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # FPS 보정 (0이면 기본값 30fps로 설정)\n",
    "    fps = fps if fps > 0 else 30\n",
    "\n",
    "    # OpenCV VideoWriter를 사용하여 임시 AVI 파일 저장\n",
    "    temp_out_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".avi\").name\n",
    "    temp_final_out = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\").name  # 최종 변환된 MP4 파일\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # 'XVID'는 대부분의 OS에서 호환됨\n",
    "    out = cv2.VideoWriter(temp_out_path, fourcc, fps, (width, height))\n",
    "\n",
    "    frame_count = 0\n",
    "    frames = []\n",
    "    results_cache = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_skip == 0:\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) >= 4:\n",
    "                results = model.predict(frames, imgsz=640, device=device, save=False)\n",
    "                results_cache.extend(results)\n",
    "                frames = []\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    if frames:\n",
    "        results = model.predict(frames, imgsz=640, device=device, save=False)\n",
    "        results_cache.extend(results)\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_skip == 0:\n",
    "            result_frame = results_cache.pop(0).plot()\n",
    "            result_frame = cv2.cvtColor(result_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if result_frame.dtype != np.uint8:\n",
    "                result_frame = (result_frame * 255).astype(np.uint8)\n",
    "\n",
    "            out.write(result_frame)\n",
    "        else:\n",
    "            out.write(frame)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # `subprocess`를 사용하여 ffmpeg로 MP4 변환\n",
    "    subprocess.run([\n",
    "        \"/Users/k23070952/Library/Python/3.9/lib/python/site-packages/ffmpeg\", \"-i\", temp_out_path, \"-vcodec\", \"libx264\", \"-crf\", \"23\", temp_final_out, \"-y\"\n",
    "    ], check=True)\n",
    "\n",
    "    # 변환 후 원본 AVI 파일 삭제\n",
    "    os.remove(temp_out_path)\n",
    "\n",
    "    return temp_final_out  # 변환된 MP4 파일 반환\n",
    "\n",
    "# ✅ **Gradio UI 수정 (기본 `gr.Video` 사용)**\n",
    "demo = gr.Interface(\n",
    "    fn=detect_video,\n",
    "    inputs=[\n",
    "        gr.Video(format=\"mp4\"),  # 동영상 업로드\n",
    "        gr.Slider(1, 5, value=2, step=1, label=\"Frame Skip\")  # 프레임 스킵 설정\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Video(format=\"mp4\"),  # 🚀 Gradio에서 직접 비디오 재생 가능!\n",
    "        gr.File(label=\"Download Processed Video\")  # 📥 다운로드 링크 제공\n",
    "    ],\n",
    "    title=\"YOLO Video Detection\",\n",
    "    description=\"Upload a video to detect objects using YOLO model. Adjust frame skip to speed up processing.\"\n",
    ")\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7886\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import ffmpeg\n",
    "\n",
    "# YOLO 모델 로드\n",
    "model = YOLO(\"./best.pt\")\n",
    "\n",
    "def detect_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # 비디오 정보 가져오기\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # FPS 보정 (0이면 최소 1로 설정)\n",
    "    fps = max(1, fps)  \n",
    "\n",
    "    # 임시 원본 출력 비디오 (mp4v 코덱)\n",
    "    temp_out_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\").name\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  \n",
    "    out = cv2.VideoWriter(temp_out_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # YOLO 모델 예측\n",
    "        results = model.predict(frame, imgsz=1280, save=False, device=\"mps\")\n",
    "        result_frame = results[0].plot()\n",
    "        \n",
    "        # 결과 프레임 저장 (float 형식일 경우 uint8로 변환)\n",
    "        if result_frame.dtype != np.uint8:\n",
    "            result_frame = (result_frame * 255).astype(np.uint8)\n",
    "        \n",
    "        out.write(result_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    # ✅ 비디오를 H.264 (AVC) 코덱으로 변환 (브라우저 호환)\n",
    "    temp_h264_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\").name\n",
    "    ffmpeg.input(temp_out_path).output(temp_h264_path, vcodec=\"libx264\", crf=23).run(overwrite_output=True)\n",
    "    \n",
    "    # 원본 임시 파일 삭제\n",
    "    os.remove(temp_out_path)\n",
    "\n",
    "    return temp_h264_path  # 변환된 비디오 경로 반환\n",
    "\n",
    "# Gradio UI 설정\n",
    "demo = gr.Interface(\n",
    "    fn=detect_video,\n",
    "    inputs=gr.Video(format=\"mp4\"),\n",
    "    outputs=gr.Video(format=\"mp4\"),  \n",
    "    title=\"YOLO Video Detection\",\n",
    "    description=\"Upload a video to detect objects using YOLO model.\"\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: ffmpeg 1.4\n",
      "Uninstalling ffmpeg-1.4:\n",
      "  Successfully uninstalled ffmpeg-1.4\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ffmpeg-python in /Users/k23070952/Library/Python/3.9/lib/python/site-packages (0.2.0)\n",
      "Requirement already satisfied: future in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from ffmpeg-python) (0.18.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall ffmpeg -y\n",
    "!pip install ffmpeg-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: ffmpeg\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -version\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
