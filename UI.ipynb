{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO(\"./best.pt\")\n",
    "\n",
    "def detect_image(image):\n",
    "    model = YOLO(\"./best.pt\")  # ëª¨ë¸ ë¡œë“œ\n",
    "    results = model.predict(image, imgsz=1280, save=False)  # YOLO ì˜ˆì¸¡ ì‹¤í–‰\n",
    "    \n",
    "    result_image = results[0].plot()  # ì˜ˆì¸¡ ê²°ê³¼ ì´ë¯¸ì§€ ë³€í™˜\n",
    "    return result_image  # ê²°ê³¼ ë°˜í™˜\n",
    "\n",
    "# Gradio UI ì„¤ì •\n",
    "demo = gr.Interface(\n",
    "    fn=detect_image,  # ì´ë¯¸ì§€ ë¶„ì„ í•¨ìˆ˜\n",
    "    inputs=gr.Image(type=\"numpy\"),  # ì…ë ¥: ì´ë¯¸ì§€ ì—…ë¡œë“œ\n",
    "    outputs=gr.Image(type=\"numpy\"),  # ì¶œë ¥: ë¶„ì„ëœ ì´ë¯¸ì§€\n",
    "    title=\"YOLO Image Detection\",  # UI ì œëª©\n",
    "    description=\"Upload an image to detect objects using YOLO model.\"\n",
    ")\n",
    "\n",
    "demo.launch(share=True)  # UI ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputting Data as a File!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 54\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# íŒŒì¼ ì—…ë¡œë“œ í›„ ì‹¤í–‰ (í”„ë ˆì„ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     video_input\u001b[38;5;241m.\u001b[39mupload(\n\u001b[1;32m     49\u001b[0m         fn\u001b[38;5;241m=\u001b[39mdetect_video_stream,\n\u001b[1;32m     50\u001b[0m         inputs\u001b[38;5;241m=\u001b[39m[video_input],\n\u001b[1;32m     51\u001b[0m         outputs\u001b[38;5;241m=\u001b[39m[video_output],\n\u001b[1;32m     52\u001b[0m     )\n\u001b[0;32m---> 54\u001b[0m demo\u001b[38;5;241m.\u001b[39mlaunch(share\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/gradio/blocks.py:2701\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[0;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, _frontend)\u001b[0m\n\u001b[1;32m   2699\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2701\u001b[0m         share_url \u001b[38;5;241m=\u001b[39m networking\u001b[38;5;241m.\u001b[39msetup_tunnel(\n\u001b[1;32m   2702\u001b[0m             local_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_name,\n\u001b[1;32m   2703\u001b[0m             local_port\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_port,\n\u001b[1;32m   2704\u001b[0m             share_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_token,\n\u001b[1;32m   2705\u001b[0m             share_server_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_server_address,\n\u001b[1;32m   2706\u001b[0m         )\n\u001b[1;32m   2707\u001b[0m         parsed_url \u001b[38;5;241m=\u001b[39m urlparse(share_url)\n\u001b[1;32m   2708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url \u001b[38;5;241m=\u001b[39m urlunparse(\n\u001b[1;32m   2709\u001b[0m             (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_server_protocol,) \u001b[38;5;241m+\u001b[39m parsed_url[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m   2710\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/gradio/networking.py:47\u001b[0m, in \u001b[0;36msetup_tunnel\u001b[0;34m(local_host, local_port, share_token, share_server_address)\u001b[0m\n\u001b[1;32m     45\u001b[0m     remote_port \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(remote_port)\n\u001b[1;32m     46\u001b[0m tunnel \u001b[38;5;241m=\u001b[39m Tunnel(remote_host, remote_port, local_host, local_port, share_token)\n\u001b[0;32m---> 47\u001b[0m address \u001b[38;5;241m=\u001b[39m tunnel\u001b[38;5;241m.\u001b[39mstart_tunnel()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m address\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/gradio/tunneling.py:103\u001b[0m, in \u001b[0;36mTunnel.start_tunnel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_tunnel\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_binary()\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_tunnel(BINARY_PATH)\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/gradio/tunneling.py:138\u001b[0m, in \u001b[0;36mTunnel._start_tunnel\u001b[0;34m(self, binary)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(\n\u001b[1;32m    135\u001b[0m     command, stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m atexit\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill)\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_url_from_tunnel_stream()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/gradio/tunneling.py:160\u001b[0m, in \u001b[0;36mTunnel._read_url_from_tunnel_stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[1;32m    161\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m line \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import uuid\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLO ëª¨ë¸ ë¡œë“œ\n",
    "model = YOLO(\"./best.pt\")\n",
    "\n",
    "# ë¹„ë””ì˜¤ í”„ë ˆì„ ì²˜ë¦¬ë¥¼ ìœ„í•œ í•¨ìˆ˜\n",
    "def process_frame(frame):\n",
    "    \"\"\" YOLO ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í”„ë ˆì„ì„ ê°ì§€í•˜ê³ , ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦° í›„ ë°˜í™˜ \"\"\"\n",
    "    results = model.predict(frame, imgsz=1280, save=False, device=\"mps\")  # Mac MPS ì‚¬ìš©\n",
    "    result_frame = results[0].plot()\n",
    "\n",
    "    # ê²°ê³¼ í”„ë ˆì„ì´ float í˜•ì‹ì´ë¼ë©´ uint8ë¡œ ë³€í™˜\n",
    "    if result_frame.dtype != np.uint8:\n",
    "        result_frame = (result_frame * 255).astype(np.uint8)\n",
    "\n",
    "    return result_frame\n",
    "\n",
    "# ë¹„ë””ì˜¤ ê°ì§€ í•¨ìˆ˜ (Gradio ìŠ¤íŠ¸ë¦¬ë° ì§€ì›, FFmpeg ì—†ì´)\n",
    "def detect_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # ë¹„ë””ì˜¤ ì†ì„± ê°€ì ¸ì˜¤ê¸°\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fps = max(1, fps)  # FPSê°€ 0ì´ë©´ ìµœì†Œ 1ë¡œ ì„¤ì •\n",
    "\n",
    "    # UUID ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±\n",
    "    output_video_name = f\"output_{uuid.uuid4()}.avi\"  # AVIë¡œ ì €ì¥í•˜ì—¬ FFmpeg í•„ìš” ì—†ìŒ\n",
    "\n",
    "    # MP4 ëŒ€ì‹  AVI ì‚¬ìš© (Gradioê°€ AVI ì§€ì›)\n",
    "    video_codec = cv2.VideoWriter_fourcc(*\"XVID\")  \n",
    "    output_video = cv2.VideoWriter(output_video_name, video_codec, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        processed_frame = process_frame(frame)  # YOLO ê°ì§€ ìˆ˜í–‰\n",
    "        output_video.write(processed_frame)  # ê²°ê³¼ ì €ì¥\n",
    "\n",
    "    cap.release()\n",
    "    output_video.release()\n",
    "\n",
    "    return output_video_name  # ìµœì¢… ë¹„ë””ì˜¤ ë°˜í™˜\n",
    "\n",
    "# Gradio UI ì„¤ì •\n",
    "with gr.Blocks() as demo:\n",
    "    gr.HTML(\"<h1 style='text-align: center'>YOLO Video Detection</h1>\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            video_input = gr.Video(label=\"Upload Video\")\n",
    "        with gr.Column():\n",
    "            output_video = gr.File(label=\"Download Processed Video\")  # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•˜ë„ë¡ ë³€ê²½\n",
    "    \n",
    "    # íŒŒì¼ ì—…ë¡œë“œ í›„ ì‹¤í–‰\n",
    "    video_input.upload(\n",
    "        fn=detect_video,\n",
    "        inputs=[video_input],\n",
    "        outputs=[output_video],\n",
    "    )\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-time detection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "Could not create share link. Missing file: /Users/k23070952/.local/lib/python3.12/site-packages/gradio/frpc_darwin_arm64_v0.3. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_darwin_arm64\n",
      "2. Rename the downloaded file to: frpc_darwin_arm64_v0.3\n",
      "3. Move the file to this location: /Users/k23070952/.local/lib/python3.12/site-packages/gradio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLO ëª¨ë¸ ë¡œë“œ\n",
    "model = YOLO(\"./best.pt\")\n",
    "\n",
    "# ë¹„ë””ì˜¤ ê°ì§€ í•¨ìˆ˜ (í”„ë ˆì„ ìŠ¤í‚µ ì¶”ê°€)\n",
    "def detect_video_stream(video_path, frame_skip=2):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_count = 0  # í”„ë ˆì„ ì¹´ìš´íŠ¸ ì´ˆê¸°í™”\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # í”„ë ˆì„ ìŠ¤í‚µ ì ìš© (í”„ë ˆì„ì„ ê±´ë„ˆë›°ë©´ì„œ ì²˜ë¦¬)\n",
    "        if frame_count % frame_skip == 0:\n",
    "            # YOLO ê°ì§€ ìˆ˜í–‰\n",
    "            results = model.predict(frame, imgsz=1280, save=False, device=\"mps\")  # Mac MPS ì‚¬ìš©\n",
    "            result_frame = results[0].plot()\n",
    "\n",
    "            # OpenCVì˜ BGRì„ RGBë¡œ ë³€í™˜ (Gradioì—ì„œ ì •ìƒ í‘œì‹œë˜ë„ë¡)\n",
    "            result_frame = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # numpy ë°°ì—´ì„ ë°˜í™˜ (Gradio `gr.Image`ì—ì„œ ì •ìƒ í‘œì‹œ ê°€ëŠ¥)\n",
    "            yield result_frame\n",
    "        \n",
    "        frame_count += 1  # í”„ë ˆì„ ì¹´ìš´íŠ¸ ì¦ê°€\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Gradio UI ì„¤ì • (Start AI Detection! ë²„íŠ¼ ì¶”ê°€)\n",
    "with gr.Blocks() as demo:\n",
    "    gr.HTML(\"<h1 style='text-align: center; font-size: 24px;'>ğŸš€ YOLO Video Detection (Real-Time Streaming)</h1>\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "                gr.Markdown(\"### ğŸ¥ Upload Your Video\")\n",
    "                video_input = gr.Video(label=\"Upload Video\")\n",
    "                frame_skip_slider = gr.Slider(\n",
    "                    minimum=1, maximum=10, step=1, value=2, \n",
    "                    label=\"ğŸï¸ Frame Skip (Higher = Faster Processing)\"\n",
    "                )\n",
    "                start_button = gr.Button(\"ğŸš€ Start AI Detection!\", variant=\"primary\")  # ì‹¤í–‰ ë²„íŠ¼ ì¶”ê°€\n",
    "\n",
    "        with gr.Column():\n",
    "                gr.Markdown(\"### ğŸ“Š Processed Video Stream\")\n",
    "                video_output = gr.Image(label=\"Processed Video\", streaming=True, height=480)  # ì›ë˜ëŒ€ë¡œ ìœ ì§€\n",
    "    \n",
    "    # \"Start AI Detection!\" ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ê°ì§€ ì‹¤í–‰\n",
    "    start_button.click(\n",
    "        fn=detect_video_stream,\n",
    "        inputs=[video_input, frame_skip_slider],  # í”„ë ˆì„ ìŠ¤í‚µ ì˜µì…˜ ì¶”ê°€\n",
    "        outputs=[video_output],\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
